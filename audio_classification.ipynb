{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "  File \"/var/folders/6s/dtgkry_95f32vht4_5w_mqfh0000gn/T/ipykernel_2710/1219367603.py\", line 11, in <module>\n",
      "    df = pd.read_csv(metadata_file_path)\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 948, in read_csv\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 611, in _read\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1448, in __init__\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1705, in _make_engine\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pandas/io/common.py\", line 863, in get_handle\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/anjalikumari/my_projects/Audio-Classification/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 90, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1114, in get_records\n",
      "  File \"/Users/anjalikumari/my_projects/Audio-Classification/venv/lib/python3.10/site-packages/pygments/styles/__init__.py\", line 92, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "# ----\n",
    "# Prepare training data from Metadata file\n",
    "#----\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "download_folder_path = Path.cwd()/'UrbanSound8K'\n",
    "# read metadata file\n",
    "metadata_file_path = download_folder_path/'metadata'/'UrbanSound8K.csv'\n",
    "df = pd.read_csv(metadata_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct file path by concatinating 'fold' and 'slice_file_name'\n",
    "df['relative_file_path'] = '/fold' + df['fold'].astype(str) + '/' + df['slice_file_name'].astype(str)\n",
    "\n",
    "# Take relevant columns\n",
    "df = df[['relative_file_path', 'classID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read audio from a file\n",
    "#### Convert to two channels\n",
    "#### Standardize sampling rate\n",
    "#### Resize to the same length\n",
    "#### Data Augmentation : time shift\n",
    "#### Mel Spectrogram\n",
    "#### Data Augmentation : time and frequency masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "\n",
    "class AudioUtil():\n",
    "    # ----\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate.\n",
    "    # ----\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "    \n",
    "    # ----\n",
    "    # Convert the given audio to the desired number of channels.\n",
    "    # ----\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sig.shape[0] == new_channel):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "        \n",
    "        if (new_channel == 1):\n",
    "            # Convert from stereo to mono by selecting only the first channel\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            # Convert from mono to stereo by duplicating the first channel\n",
    "            resig = torch.cat([sig,sig])\n",
    "        \n",
    "        return ((resig, sr))\n",
    "    \n",
    "    # ----\n",
    "    # Since resammple applies to a single channel, we resammple one channel at a time\n",
    "    # ----\n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        sig, sr = aud\n",
    "\n",
    "        if (sr == newsr):\n",
    "            # Nothing to do\n",
    "            return aud\n",
    "        \n",
    "        num_channels = sig.shape[0]\n",
    "        # Resample first channel\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        if (num_channels > 1):\n",
    "            # Resample the second channel and merge both channels\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "\n",
    "        return ((resig, newsr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
